@misc{main,
  doi = {10.48550/ARXIV.1505.05770},
  url = {https://arxiv.org/abs/1505.05770},
  author = {Rezende, Danilo Jimenez and Mohamed, Shakir},
  keywords = {Machine Learning (stat.ML), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), Computation (stat.CO), Methodology (stat.ME), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Variational Inference with Normalizing Flows},
  publisher = {arXiv},
  year = {2015},
  copyright = {arXiv.org perpetual, non-exclusive license}
},
@misc{nice,
  doi = {10.48550/ARXIV.1410.8516},
  url = {https://arxiv.org/abs/1410.8516},
  author = {Dinh, Laurent and Krueger, David and Bengio, Yoshua},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {NICE: Non-linear Independent Components Estimation},
  publisher = {arXiv},
  year = {2014},
  copyright = {arXiv.org perpetual, non-exclusive license}
},
@article{mnist,
  author = {LeCun, Yann and Cortes, Corinna},
  howpublished = {http://yann.lecun.com/exdb/mnist/},
  title = {The {MNIST} database of handwritten digits},
  url = {http://yann.lecun.com/exdb/mnist/},
  year = {1998}
},
@book{bishop,
author = {Bishop, Christopher M.},
title = {Pattern Recognition and Machine Learning (Information Science and Statistics)},
year = {2006},
isbn = {0387310738},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg}
},
@inproceedings{conv_flow,
 author = {Karami, Mahdi and Schuurmans, Dale and Sohl-Dickstein, Jascha and Dinh, Laurent and Duckworth, Daniel},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Invertible Convolutional Flow},
 url = {https://proceedings.neurips.cc/paper/2019/file/b1f62fa99de9f27a048344d55c5ef7a6-Paper.pdf},
 volume = {32},
 year = {2019}
},
@misc{stochasticVI,
  doi = {10.48550/ARXIV.1206.7051},
  url = {https://arxiv.org/abs/1206.7051},
  author = {Hoffman, Matt and Blei, David M. and Wang, Chong and Paisley, John},
  keywords = {Machine Learning (stat.ML), Artificial Intelligence (cs.AI), Computation (stat.CO), Methodology (stat.ME), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Stochastic Variational Inference},
  publisher = {arXiv},
  year = {2012},
  copyright = {arXiv.org perpetual, non-exclusive license}
},
@article{flows_review,
	doi = {10.1109/tpami.2020.2992934},
	url = {https://doi.org/10.1109%2Ftpami.2020.2992934},
	year = 2021,
	month = {nov},
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {43},
	number = {11},
	pages = {3964--3979},
	author = {Ivan Kobyzev and Simon J.D. Prince and Marcus A. Brubaker},
	title = {Normalizing Flows: An Introduction and Review of Current Methods},
	journal = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence}
},
@inproceedings{inf_flows,
author = {Welling, Max and Teh, Yee Whye},
title = {Bayesian Learning via Stochastic Gradient Langevin Dynamics},
year = {2011},
isbn = {9781450306195},
publisher = {Omnipress},
address = {Madison, WI, USA},
booktitle = {Proceedings of the 28th International Conference on International Conference on Machine Learning},
pages = {681–688},
numpages = {8},
location = {Bellevue, Washington, USA},
series = {ICML'11}
},
@inproceedings{autoregressive,
 author = {Kingma, Durk P and Salimans, Tim and Jozefowicz, Rafal and Chen, Xi and Sutskever, Ilya and Welling, Max},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Improved Variational Inference with Inverse Autoregressive Flow},
 url = {https://proceedings.neurips.cc/paper/2016/file/ddeebdeefdb7e7e7a697e1c3e3d8ef54-Paper.pdf},
 volume = {29},
 year = {2016}
},
@inproceedings{maf,
 author = {Papamakarios, George and Pavlakou, Theo and Murray, Iain},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Masked Autoregressive Flow for Density Estimation},
 url = {https://proceedings.neurips.cc/paper/2017/file/6c1da886822c67822bcf3679d04369fa-Paper.pdf},
 volume = {30},
 year = {2017}
},
@misc{flow_gan,
  doi = {10.48550/ARXIV.1705.08868},
  url = {https://arxiv.org/abs/1705.08868},
  author = {Grover, Aditya and Dhar, Manik and Ermon, Stefano},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Neural and Evolutionary Computing (cs.NE), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Flow-GAN: Combining Maximum Likelihood and Adversarial Learning in Generative Models},
  publisher = {arXiv},
  year = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
},
@inproceedings{wass,
author = {Arjovsky, Martin and Chintala, Soumith and Bottou, L\'{e}on},
title = {Wasserstein Generative Adversarial Networks},
year = {2017},
publisher = {JMLR.org},
abstract = {We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to different distances between distributions.},
booktitle = {Proceedings of the 34th International Conference on Machine Learning - Volume 70},
pages = {214–223},
numpages = {10},
location = {Sydney, NSW, Australia},
series = {ICML'17}
}


