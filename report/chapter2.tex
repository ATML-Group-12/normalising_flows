\chapter{Experiments}

\section*{NICE}

Using the idea of flows, the authors view the coupling layers in the NICE paper as a flow. A coupling layer $f$ is a neural network layer with easy to compute inverse and a trivial Jacobian. For an input vector $\mathbf{z} \in \mathbb{R}^D$, we have
\begin{align*}
    f(\mathbf{z}) &= (\mathbf{z}_A, g(\mathbf{z}_B,h(\mathbf{z}_A)))\\
    f^{-1}(\mathbf{z}) &= (\mathbf{z}_A, g^{-1}(\mathbf{z}_B,h(\mathbf{z}_A)))
\end{align*}

where $(A,B)$ is a partition of $\{1,2,\dots,D\}$, $h$ is an arbitrary function with input size $|A|$, and $g$ is a coupling law, a function that is invertible for the first argument given the second. In the paper, $h$ is a neural network and $g(a,b)=a+b$, so the Jacobian is just the identity matrix. Since the determinant of the Jacobian is 1, the authors of (variation paper) classify it as a volume-preserving flow.
The authors of the NICE paper do point out this issue, and introduce a diagonal scaling layer as the last layer of their models. This approach was not used in the original paper. Moreover, the authors introduced variants NICE-ortho and NICE-perm instead of the original directly, where random orthogonal and permutation matrices are applied to $\mathbf{z}$ before the partition. 

We note that the authors of the original paper have not made the choice of $h$ clear in the experiments. For the replicating experiment 6.1, we have chosen $h$ to be a ReLU network of 4 layers with hidden dimensions of 2.
